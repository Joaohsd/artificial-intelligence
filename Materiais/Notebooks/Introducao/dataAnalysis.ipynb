{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0421eab7",
   "metadata": {},
   "source": [
    "# Análise de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9349059",
   "metadata": {},
   "source": [
    "A **Análise de Dados** é um campo de pesquisa muito presente no mundo atual. Isso se da pelo fato do enorme número de dados coletados, os quais podem ser trabalhados a fim de gerar resultados ótimos. De fato, saber trabalhar com estes dados requer conhecimentos acerca de probabilidade, entre outras áreas. Dessa forma, saber definir dados úteis e dados a serem descartados podem acelerar o processo de treinamento do modelo de Machine Learning ao qual deseja-se treinar. Além disso, em inúmeros casos o redimensionamento da quantidade de atributos (features) pode facilitar tal processo, seja através do descarte ou pelo resumo destes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99426453",
   "metadata": {},
   "source": [
    "## **Tratando os Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a156eb28",
   "metadata": {},
   "source": [
    "O **pré-processamento** dos dados é de suma importância para sua análise, uma vez que os dados foram tratados para serem utilizados durante o treinamento do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ea63ca",
   "metadata": {},
   "source": [
    "# **Redução de Dimensionalidade**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6792bab",
   "metadata": {},
   "source": [
    "A **Redução de Dimensionalidade** tem por objetivo reduzir o número de features do seu conjunto de features. Imagine um conjunto de dados com 100 colunas (features) e reduzimos tal para 20 colunas. Tal redução permite que se tenha dados resumidos, o que facilita o treinamento de um modelo de Machine Learning, visto este modelo sendo treinado com um grande conjunto de atributos tende a ser altamente dependente dos dados utilizados em seu treinamento, resultando em uma performance ruim com dados reais. Dessa maneira, quanto maior o número de features, mais complexo pode se tornar o modelo e mais tempo será necessário para o seu treinamento. Além disso, quanto maior o número de features, mais amostras são necessárias.\n",
    "\n",
    "<center><img src=\"img/featureComplexidade.png\" alt=\"Drawing\" style=\"width: 420px;height: 300px\"/></center>\n",
    "\n",
    "**Tal processo pode ser feito de várias maneiras, retirando features ou combinando-as para gerar novas features. Tais métodos são explicados abaixo:**\n",
    "\n",
    "<center><img src=\"img/selecaoFeatures.png\" alt=\"Drawing\" style=\"width: 550px;height: 350px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6dfdff",
   "metadata": {},
   "source": [
    "## **Métodos para retirar features:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5118cf",
   "metadata": {},
   "source": [
    "Esse método mantém as features mais importante e descarta as que são redundantes do seu dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb9f4ea",
   "metadata": {},
   "source": [
    "### **Método de seleção de features:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395c163",
   "metadata": {},
   "source": [
    "Este método tem por objetivo **identificar e selecionar os atributos que são relevantes** para o treinamento do modelo. Imagine que se deseja estimar o peso de uma pessoa, talvez, não seja interessante realizar o treinamento com a feature de cor da pele. Por outro lado, o atributo altura pode contribuir e muito para o treinamento.\n",
    "Tal processo pode ser feito manualmente, baseado na relevância identificada pela pessoa a qual está analisando o dataset. Ainda assim, quando isso não é possível, faz se uso de outras ferramentas, as quais são citadas abaixo:\n",
    "*    Utilizar um mapa de calor que mostre a correlação entre as features;\n",
    "*    Plotar um gráfico que relacione cada feature com a variável alvo;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b3f17",
   "metadata": {},
   "source": [
    "Ainda é possível aplicar tal metodologia usando bibliotecas com recursos prontos, sendo uma delas a **sci-kit learn**. Um recurso dessa biblioteca é citado abaixo:\n",
    "\n",
    "*    **Limite de variação:** Tal método realiza o descarte das informações irrelevantes, baseado na variância a qual tal feature posssui. A partir disso, ele elimina as features, as quais sua própria variância não excede um determinado limite pré-estabelecido. Abaixo um exemplo, o qual descarta a primeira e a última coluna do dataset, visto que o limiar definido é **0**, pois não foi passado nada para o método \"VarianceThreshold()\". O limiar é definido pelo argumento passado para o método. Para mais informações sobre tal processo acesse o <a link=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html\">link</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f082223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [1, 4],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n",
    "selector = VarianceThreshold()\n",
    "selector.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f9b7d",
   "metadata": {},
   "source": [
    "Outro recurso da biblioteca do **sci-kit learn** é o:\n",
    "*    **Seleção Univariada:** A Seleção Univariada de features usa testes estatísticos para selecioná-las. Este método descreve um tipo de dado que consiste em observações em apenas uma única característica ou atributo. A seleção de feature univariado examina cada feature individualmente para determinar a força do relacionamento da feature com a variável de resposta. Alguns exemplos de testes estatísticos que podem ser usados para avaliar a relevância das características são Correlação de Pearson, Coeficiente de informação máxima, Correlação de distância, ANOVA e Chi-square. Chi-square é usado para encontrar a relação entre variáveis categóricas e Anova é preferida quando as variáveis são contínuas. Para mais informações sobre tal método, acesse o <a link=\"https://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html\">link</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23198898",
   "metadata": {},
   "source": [
    "## **Métodos para combinar features:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ee6f2",
   "metadata": {},
   "source": [
    "### **Métodos lineares:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c22a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
